<hr />

<p>layout: guide
navgroup: guide
group: guidechapter
section: I. Theory
title: 1. Introduction
excerpt: &#8220;xx&#8221;</p>

<h2 id="abstract:fieldguide">abstract: &#8220;Field Guide&#8221;</h2>

<p>{% include JB/setup %}</p>

<h1 id=".introduction:theneedfordisasterriskmanagementdata">1.    Introduction: The Need for Disaster Risk Management Data</h1>

<!-- ## What problems does this approach address? -->
<!-- introduce the core concepts of risk here, as if we are handing the guide to a person entirely new with GFDRR, DRR, and risk management -->

<h2 id="understandingrisk">Understanding Risk</h2>

<p>Disasters reveal chains of decisions about risk (NHUD, 2011). When infrastructure fails under strain of an earthquake, journalists may point to the failure of the construction firm to adhere to building standards. Or to the failure of a government to set and enforce code around retrofitting a school to seismic risks. Or to the owner of a factory to have inquired into the exposure of the structure to hazards and developed a strategy to cope with these potential vulnerabilities. </p>

<!-- ~~~ ~~~ ~~~ SIDEBAR  ~~~ ~~~ ~~~ -->

<div class="info-box image-right adapted width-250px">
<h4>Natural Hazards, UnNatural Disasters</h4>
<p>Every disaster is unique, but each exposes actions&mdash;by individuals and governments at different levels&mdash;that, had they been different, would have resulted in fewer deaths and less damage.</p>
</div>

<!--  ~~~ ~~~ ~~~ END SIDEBAR  ~~~ ~~~ ~~~ -->

<p>In each case, the critical element is missing information. Information that might have driven a different choice about architectural designs, building materials, or the site for the building (siting). Information that might have driven a community to question choices. Information that might have driven a legislature to pass codes or officials to allocate staff time to enforcing them. </p>

<p>Across the disaster risk management cycle, institutions are now engaged in a process to build this stock of information. The aim is to improve the chain of decision across entire ecosystem, from the donor who funds retrofitting of schools to the individual business person who need to mitigate potential losses from natural hazards while caring for his or her household. </p>

<div class="info-box image-right adapted width-200px">
<h4>Resilience</h4>
<p>OpenDRI works on a definition of resilience where informed mitigation prior to a disaster provides a buffer against the loss of human life and property when a hazard occurs. Information about the environment and likely places of failure also can improve response operations and target efforts at saving lives. OpenDRI also engages donors who fund recovery and reconstruction so that nations can build back better than before. Before, during, and after a disaster, information exposes decision makers to outcomes that would otherwise remain invisible.</p>
</div>

<hr />

<h2 id="riskassessmentandcommunication">Risk Assessment and Communication</h2>

<p>While governments may be able to model hazards, few have the ability to take this curiousity the next step: to model how this energy will impact the built environment and human systems. Risk assessment requires data about both hazards and the exposure of the built environment to specific hazards to measure vulnerability of infrastructure to specific threats. This process requires curation of three dynamic datasets:</p>

<ol>
<li><p><strong>Hazard Data</strong>: a set of historical models and forecasts for hydro-met, seismic, climate, and volcanic dynamics.</p></li>
<li><p><strong>Exposure Data</strong>: a dataset about the built environment specifically collected around the metrics necessary to calculating the vulnerability of a building or infrastructure to a specific natural hazard. These data change with the rate of urbanization and retrofitting. After a disaster, they must be updated to reflect the new built environment. </p></li>
<li><p><strong>Vulnerability Data</strong>: a calculated dataset that shows the effect that one or more hazards will have on the a dynamic built environment.</p></li>
</ol>

<p>When countries have all three datasets under management, it is possible to engage in risk assessment: an examination of the primary risks posed by probable futures and strategic planning to mitigate those risks with retrofitting, building codes, and other forms of mitigation, such as drainage, irrigation, seawalls, and other major infrastructure.</p>

<p>(note to information designer: build info graphic on how these models come together to form a triad that leads to risk assessment, and how higher resolutions improve accuracy of the models. )</p>

<p><img id="alttext" src="/assets/images/risk_hazard_exp_vul.png" alt="alt text" title="Risk Assessment Triad: Hazards, Exposure, Vulnerability" /></p>

<hr />

<h2 id="challenges:constraintsontheapplicationofinformationtoriskmanagement">Challenges: Constraints on the application of information to risk management</h2>

<p>Most countries lack the resources, training, and software to place all three types of data under a management process that allows for the assessment and mediation of risk. In many nations, the information necessary to catalyze this type of risk management thinking is blocked by a range of problems, including:</p>

<h3 id="fragmentationofspecialists">Fragmentation of Specialists</h3>

<p>Risk requires multidisciplinary analysis, but these experts rarely sit in one organization. Specialization has driven the design of modern bureaucracy towards hierarchies. Great strength for transactions and coordination of workflows, but information raises challenge. Cross-cutting horizontal flows of information needed across specializations to coordinate decisions. Design of hierarchies often forces these flows through gates or up-then-down-and-across structures. </p>

<h3 id="datafragmentation">Data Fragmentation</h3>

<p>Multidisciplinary analysis requires data from across specializations, yet these data are often segmented into silos. May be in proprietary formats, locked under intellectual property licenses that require expensive payments. Some ministries charge other parts of their own governments for use of the data. </p>

<!-- ~~~ ~~~ ~~~ SIDEBAR  ~~~ ~~~ ~~~ -->

<div class="info-box image-right adapted width-250px">
<h4>Superstorm Sandy in NYC: Unexpected vulnerabilities</h4>
<p>Even NYC had problems with exposure data. While it was possible to model potential flood inundation with relative accuracy, no one can calculated how a change in policy around generators and cold storage would affect the built environment. The major telco switching facility in Manhattan had once stored its fuel on the roof, next to the generator. A decade ago, the law changed, forcing the storage of fuel into the basement. When the flooding from Sandy hit, the fuel was under seawater, and the electrical pump that pushed fuel to the roof-top generator failed, leaving a facility that served over 10 million people without the capability of generating backup power. Staff had to hand-carry diesel fuel up 23 stories to the roof.</p>
</div>

<!-- ~~~ ~~~ ~~~ END SIDEBAR  ~~~ ~~~ ~~~ -->

<h3 id="dataduplication">Data Duplication</h3>

<p>While donors may not set out to fund two or more collections of the same data, the result of having closed data is often just that. One ministry does not know what that other has or is currently collecting. This problem becomes more acute when NGOs are involved, and communication across sectors is not as good as it might be. Fusion separate datasets may not be possible, or may be very costly, if the groups are using different standards, software, and practices around its collection and quality assurance.</p>

<h3 id="dataaccess">Data Access</h3>

<p>Data may be available, but it might be limited to use by specific parties. Access is discriminatory.</p>

<h3 id="datastalenessandincompleteness">Data Staleness and Incompleteness</h3>

<p>Data may reflect best knowledge from investment made more than decade before. In some countries, the last census or survey-quality map may be decades old. Data about exposure may have never been collected at the level of resolution necessary to build risk models. Data is outdated and/or incomplete.</p>

<h3 id="exposuredatacanbeexpensivetocollectandmaintain">Exposure Data can be Expensive to collect and maintain</h3>

<p>Data about buildings and built environment is time-intensive to collect and maintain. The built environment changes at the rate of construction plus the rate of destruction. (Collective action to collect this data has become possible.)</p>

<hr />

<h2 id="policychallenge:underlyingrisksareaccelerating">Policy Challenge: underlying risks are accelerating</h2>

<p>Climate Change and urbanization are changing the nature and magnitude of risks many developing countries, particularly those most at risk of increased cyclones, floods, and droughts in cities with swelling peri-urban slums sited in the most vulnerable areas. For these policy makers, it is become ever more difficult to get a handle on dynamic risks.</p>

<!-- ~~~ ~~~ ~~~ SIDEBAR  ~~~ ~~~ ~~~ -->

<div class="info-box image-right adapted width-250px">
<h4>Case Study: Kathmandu</h4>
<p>Kathmandu Pre-OpenDRI: the need for basic map of schools and health facilities. Why we could not model seismic risks to critical infrastructure except at the macro level. Urbanization and growth rates (about 5%!). Rapid construction, low ability to enforce building codes. Ever more population at risk, more structures enter into risk pool. </p>
</div>

<!-- ~~~ ~~~ ~~~ END SIDEBAR  ~~~ ~~~ ~~~ -->

<h3 id="thatsaidevendynamicriskcanbemediatedandmanaged.">That said, even dynamic risk can be mediated and managed.</h3>

<p>The levers to manage risk are not always obvious. They may be at level of policy, such as building codes. They may require direct investments in retrofitting infrastructure to higher seismic standards. Or they may require soft infrastructure in a better prepared populace who stockpile supplies because they expect to be cut off from outside aid for a period of several weeks after the next major disaster.</p>

<h3 id="managingdynamicrisksrequireshigherresolutiondata">Managing dynamic risks requires higher resolution data</h3>

<p>Most governments function with data collected at best annually. In many places, data on the built environment have not been updated in decades, or are collected across a small sample of the country. Land cover estimates may be at greater than 1km or even 5km resolution (average building abstracted from sample across grid square.) There may be policy barriers to collecting the data, particularly where surveys of informal settlements by government officials might create political pressures to turn peri-urban slums into recognized municipalities. Yet, to assess the risk in places facing 5% annual population growth and increased probabilities of droughts, fires, floods, and landslides, governments need higher resolution data, both temporally (collection intervals) and spatially (grid square averages). </p>

<h3 id="butthecomponentsofriskassessmentarenolongeractivitiesthatmostgovernmentscanaffordtodoalonethereisanincreasingneedforcollectiveaction.">But the components of risk assessment are no longer activities that most governments can afford to do alone; there is an increasing need for collective action.</h3>

<p>To collect higher resolution data in times of economic uncertainty and tight budgets is a difficult choice. Professional surveys of urban areas can be very expensive. Analysis of the data can also be costly. But there is another way: collective action.</p>

<p>In Indonesia, Nepal, and a growing number of countries, governments have been mobilizing their ministries and citizens to collect and curate the data necessary to make everyone safer. Because much of the labor is done by community organization, the resulting maps of built environment are being created at ultra low cost. Working together, members of the private sector, public sector, and community organizations are building a shared understanding of their probable futures. With the aid of risk managers, the government is guiding a conversation about how to invest in mitigating the worst possible outcomes as a whole nation.</p>

<h3 id="thisneedforcollectiveactionisemergingattimewhencommunicationstoolsandpracticesareintroducingdisruptivechangeinthemethodsofcoordinatingcollectiveaction.">This need for collective action is emerging at time when communications tools and practices are introducing disruptive change in the methods of coordinating collective action.</h3>

<p>When communications are expensive, coordination generally occurs in centralized hierarchies, where decision makers at each level have specific authorities. Since the Internet, the costs of communications have been falling dramatically, so the point where they are now approaching zero. In parallel, ever more computing power have been concentrated in devices whose production costs are falling according to Moore&#8217;s Law. (sidebar). As a result, billions of citizens of the world have access to low cost communications via handheld devices that allow for data collection, geolocation, and photography. They can organize their operations as swarms, collective intelligences that follow resilient networks of the Internet shaped into human form. </p>

<ul class="circle">
<li>GPS </li>
<li>Cell Phones</li>
<li>Overhead imagery</li>
<li>Participatory or community mapping</li>
<li>Open geospatial platforms</li>
</ul>

<hr />

<h2 id="opendataforresilience:harnessingcollectiveaction">Open Data for Resilience: Harnessing Collective Action</h2>

<p>Integrating these opportunities and new technologies has become the mission for a two-year old initiative called Open Data for Resilience. This partnership of international institutions, client governments, and community organizations harnesses low-cost, fast-cycle efforts to collate, collect, and analyze data about natural hazards and the risks that they poses to a nation. It is the subject of the next chapter.</p>
