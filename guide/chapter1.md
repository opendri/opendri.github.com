---
layout: guide
navgroup: guide
group: guidechapter
title: 1. Introduction
excerpt: "xx"
abstract: "Field Guide"
---
{% include JB/setup %}

# 1.	Introduction: The Need for Disaster Risk Management Data

## What can risk models do?
Imagine if a national director of emergency preparedness received an email with a link to a forecast for the upcoming monsoon season. But instead of clicking on the link and viewing the information in a web page, she copied it into for in a piece of free and open source software on her desktop, which pulled the data from the forecast into a risk impact tool. This software already had a map of every house in the flood prone areas of her country's largest city, along with a flood inundation model that was programmed to understand the monsoon forecast. With a click of button, her computer begins processing the data. After a couple minutes, the impact model shows her which neighborhoods would be most likely to flood this season as well as which shelters would be likely to be flooded and unusable. 

Because the map of the exposure of the neighborhoods were collected by the residents of those areas, they are also connected into the same network. Seeing that some places are likely to be severely impacted, the National Preparedness Director initiates a process by which risk analysts release the impact model to the communities so that they can choose how they will prepare in the event major flooding comes to pass.

This scenario is no longer science fiction. All the elements exist and have been deployed in a range of countries by a growing network of partners under the moniker, Open Data for Resilience. 

## Natural Hazards, UnNatural Disasters
[ to be completed. argument from NHUD on the need for better risk information among a wide range of actors. Add to that the need for info from the G20 Disaster Risks book, Sendai Report, and HFA]


## Problem of Risk Data
Disasters reveal imprudent decisions. When infrastructure fails under strain of an earthquake, journalists may point to the failure of the construction firm to adhere to buildings standards. Or to the failure of a government to set and enforce code around retrofitting a school to seismic risks. Or to the owner of a factory to have inquired into the exposure of the structure to hazards and developed a strategy to cope with these potential vulnerabilities. In each case, the critical element is missing information. Information that might have driven a different choice about architectural designs, building materials, or the site for the building (siting). Information that might have driven a community to question choices. Information that might have driven a legislature to pass codes or officials to allocate staff time to enforcing them. 

### Fragmentation of Specialists
Risk requires multidisciplinary analysis, but these experts rarely sit in one organization. Specialization has driven the design of modern bureaucracy towards hierarchies. Great strength for transactions and coordination of workflows, but information raises challenge. Cross-cutting horizontal flows of information needed across specializations to coordinate decisions. Design of hierarchies often forces these flows through gates or up-then-down-and-across structures. 

### Data Fragmentation
Multidisciplinary analysis requires data from across specializations, yet these data are often segmented into silos. May be in proprietary formats, locked under intellectual property licenses that require expensive payments. Some ministries charge other parts of their own governments for use of the data. 

### Data Access
Data may be available, but it might be limited to use by specific parties. Access is discriminatory.

### Data Staleness and Incompleteness
Data may reflect best knowledge from investment made more than decade before. In some countries, the last census or survey-quality map may be decades old. Data about exposure may have never been collected at the level of resolution necessary to build risk models. Data is outdated and/or incomplete.

## Dynamic Nature of Risk
Not a static forecast. Complex system, dynamics are nonlinear. Shocks can have effects that are disproportionate to the energy they exert on human systems. Chile: 8.8 exerted 500 times the energy of the earthquake in Port-au-Prince, yet killed only 234 people versus over 200K citizens of Haiti. This disproportionate effect is the resilience leaders seek to build for their citizens. 

## Dynamic Risk Models Need Good Data
Yet, modeling something disproportionate--nonlinear--breaks down without good data. Timely, accurate.

## Risk information is accelerating
Climate Change, Urbanization. ever more difficult to get a handle on these dynamic flows of analysis. 

## Open Government Data and OpenDRI





In many cities, maps of buildings do not exist, or are locked away behind paywalls and stored in data formats that require expensive software to view and modify. To change the reality for the most vulnerable, data about the risks in a place need to be put into formats that are the most open, most available (...)

Failure of building reveals a system of interdependent dynamics. Choice of site may not have known that the area was in a flood zone. Architect may not have known that the type of flooding . City may not have known 

For development institutions, governments, and humanitarians, understanding the current state of things--the baseline data--in a city is the first step to being able to assess risks, mitigate them, prepare for dynamics which are expected to fail, and develop a plan to reconstruct in more resilient ways.

This guide details one approach to building this baseline information: Open Data for Resilience. Partnership that has catalogued over 1M buildings in Indonesia, mapped Kathmandu, 


The management of risk requires moving the unknown to the uncertain. Of nailing down certain bits of what can be known. 

"All models are wrong; some, however, are useful." Box's statement...

Fragmentation of information
Collective intelligence
Humpty Dumpty. All the king's horses and all the kings men...





In many parts of the world, the infrastructure on which societies rely is vulnerable to damage by natural hazards. During periods of conflict or weak government, entire neighborhoods have been constructed without adhering to building standards or have grown in areas that are particularly susceptible to floods, tsunamis, or other natural hazards. 


Actors in the disaster risk management cycle are struggling to harness new sources of data and analysis. From disaster risk reduction and preparedness to response and recovery, open data plays a role across the DRM cycle.

## Background
To articulate themes from the UN/WorldBank flagship study, *Natural Hazards, UnNatural Disasters*:

### Risk is dynamic
it changes based on the rate of change of the built environment, climate. This 

### Because risk is dynamic, it can be mediated and managed. 
But the levers are not always obvious. May be at level of policy: building codes. May require direct investments in retrofitting infrastructure to higher seismic standards. Or may require soft infrastructure in a better prepared populace who stockpile supplies because they expect to be cut off from outside aid for a period of several weeks after the next major disaster.

### Rate of change of risks is increasing. 
Rising levels of urbanization. Rate of change of climate.

### Risk is no longer something that governments can assess alone; increasing need for collective action.
Gov and private sector need collective assistance in building understanding of risks.

### This need for collective action is emerging at time when communications tools and practices are introducing disruptive change in the methods of coordinating collective action. 
<ul class="circle">
<li>GPS: </li>
<li>Cell Phones:</li>
<li>Overhead imagery: </li>
<li>Participatory or community mapping:</li>
<li>Open geospatial platforms:</li>
</ul>
Resilience can increased through relationships. Through information that activates and coordinates those relationships. Collective action.

But where to put the lever? Requires information on the hazards, exposure of the built environment to those hazards, measured as vulnerability.

### Scientists are also increasing our understanding of the natural environment and prevalence of natural hazards.  


## A shared problem: the need for better data to target DRM activities
Outline the core problem around exposure data.

1.	Hazard Data
2.	Exposure Data
3.	Vulnerability Data

Targeting DRM investments requires better exposure data. 

Collective action to collect this data has become possible.

## Case Study
Kathmandu Pre-OpenDRI: the need for basic map of schools and health facilities. Why we could not model seismic risks to critical infrastructure except at the macro level.

## Why Open Data?
Concept: empower decision makers with open systems. Create shared space where community can assembled around shared problems and develop open solutions. 

## Principles
Operating principles of open data.

1.	Legally versus Technically Open
2.	Accessible: available at a public address (URI)
3.	Interoperable: open standard
4.	Reusable: can be redistributed and reused in ways that were not necessarily anticipated by the curator of the original data.

Overall, the intent is to follow Huffman’s First Principle of Information Sharing: 
Leave data better than you found it.

### Ten Principles of Open Government Data (OGD)
(src: Linked Open Data: The Essentials, Bauer and Kaltenböck)

1. Data must be complete
2. Data must be primary
3. Data must be timely
4. Data must be accessible
5. Data must be machine-processable
6. Access must be non-discriminatory
7. Data formats must be non-proprietary
8. Data must be license free
9. Data must have permanence, be findable over time
10. usage costs must be de minimus

## Challenges
Open data is not easy to implement. There are many reasons why 
1.	Fragmentation
2.	Incompleteness
3.	Inaccuracy
4.	Transparency: politics of opening data creates visibility into processes that have not previously been transparent. Such exposure creates anxieties.
5.	Trust

## Value of Open Data
Yet, open data creates new opportunities
1.	Fusion of previously fragmented data
2.	Greater coverage and comprehensive views
3.	Community curation to correct data
4.	Trust in transparent processes
5.	Inexpensive and reusable

(potential sidebar: Open Source, Open Data, Open Standard: what’s the difference)
